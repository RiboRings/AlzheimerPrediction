{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://www.kaggle.com/code/giuliobenedetti/learning-about-ad?scriptVersionId=154307187\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"]},{"cell_type":"code","execution_count":null,"id":"19eab8cb","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:52.085084Z","iopub.status.busy":"2023-12-09T19:40:52.084657Z","iopub.status.idle":"2023-12-09T19:40:52.495532Z","shell.execute_reply":"2023-12-09T19:40:52.494627Z"},"papermill":{"duration":0.4227,"end_time":"2023-12-09T19:40:52.497797","exception":false,"start_time":"2023-12-09T19:40:52.075097","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","df_cross = pd.read_csv(\"/kaggle/input/mri-and-alzheimers/oasis_cross-sectional.csv\")\n","df_long = pd.read_csv(\"/kaggle/input/mri-and-alzheimers/oasis_longitudinal.csv\")"]},{"cell_type":"markdown","id":"65aae561","metadata":{"papermill":{"duration":0.00687,"end_time":"2023-12-09T19:40:52.513348","exception":false,"start_time":"2023-12-09T19:40:52.506478","status":"completed"},"tags":[]},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"id":"a3007224","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:52.529604Z","iopub.status.busy":"2023-12-09T19:40:52.528876Z","iopub.status.idle":"2023-12-09T19:40:52.555902Z","shell.execute_reply":"2023-12-09T19:40:52.555016Z"},"papermill":{"duration":0.037695,"end_time":"2023-12-09T19:40:52.558152","exception":false,"start_time":"2023-12-09T19:40:52.520457","status":"completed"},"tags":[]},"outputs":[],"source":["# Rename cols to match names in df_cross\n","df_long = df_long.rename(columns={\"MRI ID\": \"ID\", \"EDUC\": \"Educ\", \"MR Delay\": \"Delay\"})\n","\n","# Create columns for easy distinction between the cohorts\n","df_cross[\"Cohort\"] = \"OASIS1\"\n","df_long[\"Cohort\"] = \"OASIS2\"\n","\n","# Concatenate df_cross with df_long\n","df = pd.concat([df_cross, df_long])\n","\n","# Drop rows with missing target variable\n","df.dropna(subset=[\"CDR\"], inplace=True)\n","\n","# Remove cols with only one distinct value\n","df.drop([\"Hand\"], axis=1, inplace=True)\n","\n","# Use ID as row index\n","df.index = df.pop(\"ID\")"]},{"cell_type":"code","execution_count":null,"id":"dbc71b50","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:52.574907Z","iopub.status.busy":"2023-12-09T19:40:52.574139Z","iopub.status.idle":"2023-12-09T19:40:54.005686Z","shell.execute_reply":"2023-12-09T19:40:54.004523Z"},"papermill":{"duration":1.443113,"end_time":"2023-12-09T19:40:54.008539","exception":false,"start_time":"2023-12-09T19:40:52.565426","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.impute import SimpleImputer\n","\n","# Given a uniform distribution, impute SES with mode\n","ses_imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n","# Given a skewed distribution, impute MMSE with median\n","mmse_imputer = SimpleImputer(missing_values=np.nan, strategy=\"median\")\n","\n","# Fit imputer on SES\n","ses_imputer.fit(df[[\"SES\"]])\n","# Impute missing values in SES\n","df[\"SES\"] = ses_imputer.fit_transform(df[[\"SES\"]])\n","\n","# Fit imputer on MMSE\n","mmse_imputer.fit(df[[\"MMSE\"]])\n","# Impute missing values in MMSE\n","df[\"MMSE\"] = mmse_imputer.fit_transform(df[[\"MMSE\"]])"]},{"cell_type":"code","execution_count":null,"id":"3127b2b7","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:54.024772Z","iopub.status.busy":"2023-12-09T19:40:54.024368Z","iopub.status.idle":"2023-12-09T19:40:54.030479Z","shell.execute_reply":"2023-12-09T19:40:54.029491Z"},"papermill":{"duration":0.016626,"end_time":"2023-12-09T19:40:54.032498","exception":false,"start_time":"2023-12-09T19:40:54.015872","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn import preprocessing\n","\n","# Create LabelEncoder\n","le = preprocessing.LabelEncoder()\n","# Encode original CDR from (0, 0.5, 1, 1.5, 2) to (0, 1, 2, 3)\n","df[\"CDR\"] = le.fit_transform(df[\"CDR\"])"]},{"cell_type":"markdown","id":"154abc4d","metadata":{"papermill":{"duration":0.00683,"end_time":"2023-12-09T19:40:54.046519","exception":false,"start_time":"2023-12-09T19:40:54.039689","status":"completed"},"tags":[]},"source":["# Preliminary Exploration"]},{"cell_type":"code","execution_count":null,"id":"a6627ef1","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:54.062458Z","iopub.status.busy":"2023-12-09T19:40:54.06204Z","iopub.status.idle":"2023-12-09T19:40:54.869184Z","shell.execute_reply":"2023-12-09T19:40:54.868069Z"},"papermill":{"duration":0.817845,"end_time":"2023-12-09T19:40:54.871632","exception":false,"start_time":"2023-12-09T19:40:54.053787","status":"completed"},"tags":[]},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import seaborn as sns\n","\n","df[\"Visit\"] = df[\"Visit\"].fillna(value=1)\n","\n","ncol = 2\n","fig, axes = plt.subplots(1, ncol, sharey=True)\n","\n","fig.set_figheight(3)\n","fig.set_figwidth(8)\n","sns.set_style(\"ticks\")\n","\n","sns.countplot(df, x=\"Visit\", hue=\"Cohort\", ax=axes[0])\n","axes[0].set_xlabel(\"Visit Number\")\n","axes[0].set_ylabel(\"Count\")\n","\n","sns.countplot(df, x=\"CDR\", hue=\"M/F\", ax=axes[1])\n","axes[1].set_ylabel(\"\")\n","axes[1].legend(title=\"Sex\")\n","\n","plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"id":"63cb2e9e","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:54.889009Z","iopub.status.busy":"2023-12-09T19:40:54.8886Z","iopub.status.idle":"2023-12-09T19:40:54.899971Z","shell.execute_reply":"2023-12-09T19:40:54.899055Z"},"papermill":{"duration":0.022663,"end_time":"2023-12-09T19:40:54.902149","exception":false,"start_time":"2023-12-09T19:40:54.879486","status":"completed"},"tags":[]},"outputs":[],"source":["grouped_df = df.groupby([\"Visit\", \"CDR\"]).size()\n","size_arr = df.groupby(\"Visit\").size().values\n","\n","count_df = pd.DataFrame({\n","    \"Visit\": [i[0] for i in grouped_df.index],\n","    \"CDR\": [i[1] for i in grouped_df.index],\n","    \"Count\": grouped_df.values\n","})\n","\n","count_df[\"Percentage\"] = count_df[\"Count\"] / count_df[\"Visit\"].map(lambda x: size_arr[round(x) - 1]) * 100"]},{"cell_type":"code","execution_count":null,"id":"6311224d","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:54.919016Z","iopub.status.busy":"2023-12-09T19:40:54.918606Z","iopub.status.idle":"2023-12-09T19:40:55.262386Z","shell.execute_reply":"2023-12-09T19:40:55.261274Z"},"papermill":{"duration":0.355137,"end_time":"2023-12-09T19:40:55.264858","exception":false,"start_time":"2023-12-09T19:40:54.909721","status":"completed"},"tags":[]},"outputs":[],"source":["sns.lineplot(\n","    count_df, x=\"Visit\", y=\"Percentage\",\n","    hue=\"CDR\", palette=\"colorblind\",\n","    marker=\"o\"\n",")\n","\n","plt.xlabel(\"Visit Number\")\n","plt.xticks(range(1, 6))\n","\n","plt.ylabel(\"Relative Percentage (%)\")"]},{"cell_type":"code","execution_count":null,"id":"683f00b8","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:55.283273Z","iopub.status.busy":"2023-12-09T19:40:55.282895Z","iopub.status.idle":"2023-12-09T19:40:55.304214Z","shell.execute_reply":"2023-12-09T19:40:55.303034Z"},"papermill":{"duration":0.033381,"end_time":"2023-12-09T19:40:55.306654","exception":false,"start_time":"2023-12-09T19:40:55.273273","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn import decomposition\n","\n","X = df.drop([\"CDR\", \"Delay\", \"Subject ID\", \"Group\", \"Visit\", \"M/F\", \"Cohort\"], axis=1)\n","\n","pca = decomposition.PCA(n_components=2)\n","pca.fit(X)\n","red_dims = pca.transform(X)"]},{"cell_type":"code","execution_count":null,"id":"401d31da","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:55.32574Z","iopub.status.busy":"2023-12-09T19:40:55.325359Z","iopub.status.idle":"2023-12-09T19:40:55.33192Z","shell.execute_reply":"2023-12-09T19:40:55.330902Z"},"papermill":{"duration":0.018623,"end_time":"2023-12-09T19:40:55.334119","exception":false,"start_time":"2023-12-09T19:40:55.315496","status":"completed"},"tags":[]},"outputs":[],"source":["def plot_pca(red_dims, hue, ax, palette=\"colorblind\", s=15):\n","    \n","    sns.scatterplot(\n","    x=red_dims[:, 0], y=red_dims[:, 1],\n","    hue=hue, palette=palette,\n","    s=s, ax=ax\n","    )\n","\n","ncol, nrow = 2, 2\n","my_palette = sns.color_palette(\"viridis\", as_cmap=True)"]},{"cell_type":"code","execution_count":null,"id":"37cda70e","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:55.352549Z","iopub.status.busy":"2023-12-09T19:40:55.352141Z","iopub.status.idle":"2023-12-09T19:40:57.070285Z","shell.execute_reply":"2023-12-09T19:40:57.069228Z"},"papermill":{"duration":1.733089,"end_time":"2023-12-09T19:40:57.075394","exception":false,"start_time":"2023-12-09T19:40:55.342305","status":"completed"},"tags":[]},"outputs":[],"source":["fig, axes = plt.subplots(ncol, nrow, sharex=True, sharey=True)\n","\n","fig.set_figheight(3 * nrow)\n","fig.set_figwidth(8)\n","sns.set_style(\"ticks\")\n","\n","plot_pca(red_dims, df[\"M/F\"], axes[0, 0])\n","plot_pca(red_dims, df[\"Age\"], axes[1, 1], palette=my_palette)\n","plot_pca(red_dims, df[\"CDR\"], axes[1, 0])\n","plot_pca(red_dims, df[\"nWBV\"], axes[0, 1], palette=my_palette)\n","\n","fig.text(0.5, 0, f\"PCA1: {pca.explained_variance_ratio_[0] * 100:.1f} %\", ha=\"center\")\n","fig.text(0, 0.5, f\"PCA2: {pca.explained_variance_ratio_[1] * 100:.1f} %\", va=\"center\", rotation=\"vertical\")\n","\n","plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"id":"198fe491","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:57.102056Z","iopub.status.busy":"2023-12-09T19:40:57.100959Z","iopub.status.idle":"2023-12-09T19:40:57.567866Z","shell.execute_reply":"2023-12-09T19:40:57.566699Z"},"papermill":{"duration":0.482827,"end_time":"2023-12-09T19:40:57.570641","exception":false,"start_time":"2023-12-09T19:40:57.087814","status":"completed"},"tags":[]},"outputs":[],"source":["corr = X.corr()\n","sns.heatmap(\n","    corr, cmap=\"vlag\", annot=True,\n","    fmt=\".2f\", annot_kws={'size': 10},\n","    vmin=-1, vmax=1\n",")"]},{"cell_type":"markdown","id":"f25adf26","metadata":{"papermill":{"duration":0.01265,"end_time":"2023-12-09T19:40:57.596405","exception":false,"start_time":"2023-12-09T19:40:57.583755","status":"completed"},"tags":[]},"source":["# Baseline Performance\n","\n","_What is the minimal performance that we should expect from a model?_ This question can be answered by setting a **baseline performance**. This usually corresponds to the accuracy obtained with a very simple model, such as a classifier that predicts everything to be the most frequent class. The latter approach is applied here to estimate a baseline performance for the cross-sectional and longitudinal datasets as well as the combined dataset."]},{"cell_type":"code","execution_count":null,"id":"dcd63bc2","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:57.624062Z","iopub.status.busy":"2023-12-09T19:40:57.623658Z","iopub.status.idle":"2023-12-09T19:40:57.637854Z","shell.execute_reply":"2023-12-09T19:40:57.636838Z"},"papermill":{"duration":0.031073,"end_time":"2023-12-09T19:40:57.640303","exception":false,"start_time":"2023-12-09T19:40:57.60923","status":"completed"},"tags":[]},"outputs":[],"source":["# Split dataframe into features (X) and target (y)\n","def X_y_split(df, target=\"CDR\", drop_cols=[\"CDR\", \"Delay\", \"Subject ID\", \"Group\", \"Visit\", \"Cohort\"]):\n","    \n","    X = df.drop(drop_cols, axis=1)\n","    y = df.copy().pop(target)\n","    \n","    return X, y\n","\n","# Split preprocessed datasets\n","df_cross = df.loc[df[\"Cohort\"] == \"OASIS1\", ]\n","df_long = df.loc[df[\"Cohort\"] == \"OASIS2\", ]\n","\n","# Split X and y for combined dataset and separate datasets\n","X, y = X_y_split(df)\n","X_cross, y_cross = X_y_split(df_cross)\n","X_long, y_long = X_y_split(df_long)"]},{"cell_type":"code","execution_count":null,"id":"07deadfc","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:57.667327Z","iopub.status.busy":"2023-12-09T19:40:57.666888Z","iopub.status.idle":"2023-12-09T19:40:57.680647Z","shell.execute_reply":"2023-12-09T19:40:57.67929Z"},"papermill":{"duration":0.029693,"end_time":"2023-12-09T19:40:57.682688","exception":false,"start_time":"2023-12-09T19:40:57.652995","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.dummy import DummyClassifier\n","\n","# Compute baseline performance based on given strategy\n","def baseline_performance(X, y, strategy=\"most_frequent\"):\n","    \n","    dummy_clf = DummyClassifier(strategy=strategy)\n","    dummy_clf.fit(X, y)\n","    dummy_clf.predict(X)\n","    \n","    return dummy_clf.score(X, y)\n","\n","print(f\"Baseline performance for all data: {baseline_performance(X, y) * 100:.2f}%\")\n","print(f\"Baseline performance for cross-sectional data: {baseline_performance(X_cross, y_cross) * 100:.2f}%\")\n","print(f\"Baseline performance for longitudinal data: {baseline_performance(X_long, y_long) * 100:.2f}%\")"]},{"cell_type":"markdown","id":"07af7e80","metadata":{"papermill":{"duration":0.012794,"end_time":"2023-12-09T19:40:57.708707","exception":false,"start_time":"2023-12-09T19:40:57.695913","status":"completed"},"tags":[]},"source":["The baseline performance remains similar among the three datasets with an average of around 56%. This is the minimum accuracy that we want to achieve with a more suitable model."]},{"cell_type":"markdown","id":"d3da78d7","metadata":{"papermill":{"duration":0.012973,"end_time":"2023-12-09T19:40:57.734875","exception":false,"start_time":"2023-12-09T19:40:57.721902","status":"completed"},"tags":[]},"source":["# Preparing the tools"]},{"cell_type":"markdown","id":"96448815","metadata":{"papermill":{"duration":0.012556,"end_time":"2023-12-09T19:40:57.76029","exception":false,"start_time":"2023-12-09T19:40:57.747734","status":"completed"},"tags":[]},"source":["## Train/Test Split and Cross-Validation\n","\n","In longitudinal data, samples from the same patients are not independent, so they can cause information leakage.\n","\n","TODO: make sure that individuals are fully contained in either train or devel/test and not in both. A way is to order the df by subject ID and split without shuffling. Or also shuffle the subject IDs and then order df by this shuffled subject IDs."]},{"cell_type":"code","execution_count":null,"id":"2a3deca0","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:57.788224Z","iopub.status.busy":"2023-12-09T19:40:57.787572Z","iopub.status.idle":"2023-12-09T19:40:57.797941Z","shell.execute_reply":"2023-12-09T19:40:57.796959Z"},"papermill":{"duration":0.02702,"end_time":"2023-12-09T19:40:57.800277","exception":false,"start_time":"2023-12-09T19:40:57.773257","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn import model_selection as ms\n","\n","# Set fraction of data allocated to the test set \n","test_fraction = 0.1\n","\n","# Split train/devel set from test set\n","X_train, X_test, y_train, y_test = ms.train_test_split(\n","    X, y,\n","    test_size=test_fraction,\n","    stratify=y,\n","    random_state=123,\n",")\n","\n","# Set k equal to the number of occurrences of least populated class\n","k_folds = y.value_counts().min() - 1\n","\n","# Create stratified K-fold validator\n","skf = ms.StratifiedKFold(\n","    n_splits=k_folds,\n","    shuffle=True,\n","    random_state=123\n",")"]},{"cell_type":"markdown","id":"f33db2b5","metadata":{"papermill":{"duration":0.01226,"end_time":"2023-12-09T19:40:57.825332","exception":false,"start_time":"2023-12-09T19:40:57.813072","status":"completed"},"tags":[]},"source":["## Feature Transformation\n","\n","**Data normalisation** helps standardise features and speed up learning. Thus, data is normalised by scaling numerical variables and one-hot encoding categorical ones. Ordinal variables may also need normalisation, but options for this type have not been found yet."]},{"cell_type":"code","execution_count":null,"id":"464ec051","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:57.85226Z","iopub.status.busy":"2023-12-09T19:40:57.851859Z","iopub.status.idle":"2023-12-09T19:40:57.879407Z","shell.execute_reply":"2023-12-09T19:40:57.878437Z"},"papermill":{"duration":0.044077,"end_time":"2023-12-09T19:40:57.881905","exception":false,"start_time":"2023-12-09T19:40:57.837828","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.compose import make_column_transformer\n","\n","# Categorise variables by type\n","categorical_vars = [\"M/F\"]\n","numerical_vars = [\"Age\", \"Educ\", \"eTIV\", \"nWBV\", \"ASF\"]\n","ordinal_vars = [\"Educ\", \"SES\", \"MMSE\"]\n","\n","# Build transformer for preprocessing\n","preprocessor = make_column_transformer(\n","    (preprocessing.StandardScaler(), numerical_vars),\n","    (preprocessing.OneHotEncoder(), categorical_vars)\n",")\n","\n","# Apply transformer to data\n","X_train = preprocessor.fit_transform(X_train)\n","X_test = preprocessor.transform(X_test)"]},{"cell_type":"markdown","id":"cbf70129","metadata":{"papermill":{"duration":0.012329,"end_time":"2023-12-09T19:40:57.907059","exception":false,"start_time":"2023-12-09T19:40:57.89473","status":"completed"},"tags":[]},"source":["## Validation Metrics\n","\n","Currently, the criterion to select the most performant model is based on two validation metrics: accuracy and confusion matrix. The former gives a general measure of the classification power, whereas the latter provides a more detailed insight into the bias of the model. It may be useful to validate the models with other metrics which put more weight on the rare classes, that is, the demented subjects."]},{"cell_type":"code","execution_count":null,"id":"5778454c","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:57.93457Z","iopub.status.busy":"2023-12-09T19:40:57.93419Z","iopub.status.idle":"2023-12-09T19:40:57.940527Z","shell.execute_reply":"2023-12-09T19:40:57.939485Z"},"papermill":{"duration":0.022786,"end_time":"2023-12-09T19:40:57.942769","exception":false,"start_time":"2023-12-09T19:40:57.919983","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.metrics import accuracy_score, make_scorer, confusion_matrix\n","\n","# Perform model validation based on k-fold cross-validation\n","def validate_model(model, X, y, metric=accuracy_score, **kwargs):\n","    \n","    scorer = make_scorer(metric)\n","    score = ms.cross_val_score(\n","        model,\n","        X, y,\n","        scoring=scorer,\n","        **kwargs\n","    )\n","    \n","    return score\n","\n","# Generate confusion matrix based on k-fold cross validation\n","def make_confusion_matrix(model, X, y, **kwargs):\n","    \n","    y_pred = ms.cross_val_predict(\n","        model,\n","        X, y,\n","        **kwargs\n","    )\n","    \n","    conf_mat = confusion_matrix(y, y_pred)\n","    \n","    return conf_mat"]},{"cell_type":"markdown","id":"9a2e740d","metadata":{"papermill":{"duration":0.012958,"end_time":"2023-12-09T19:40:57.96847","exception":false,"start_time":"2023-12-09T19:40:57.955512","status":"completed"},"tags":[]},"source":["# Model Selection\n","\n","The candidate models include:\n","- cost-sensitive SVM\n","- Decision tree\n","- Random forest\n","- K neighbours\n","\n","To add a new model, you can simply import it from a package, create it and store it in the dictionary of classifiers under a name of your choice."]},{"cell_type":"code","execution_count":null,"id":"02ebad4a","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:57.995774Z","iopub.status.busy":"2023-12-09T19:40:57.99517Z","iopub.status.idle":"2023-12-09T19:40:58.095452Z","shell.execute_reply":"2023-12-09T19:40:58.09463Z"},"papermill":{"duration":0.11669,"end_time":"2023-12-09T19:40:58.097836","exception":false,"start_time":"2023-12-09T19:40:57.981146","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Prepare empty dictionary to store models\n","models = {}\n","\n","# Create SVM classifier and add to dictionary\n","models[\"SVM\"] = SVC(kernel=\"rbf\", class_weight=\"balanced\")\n","# Create decision tree classifier and add to dictionary\n","models[\"Tree\"] = DecisionTreeClassifier(random_state=123)\n","# Create random forest classifier\n","models[\"Random Forest\"] = RandomForestClassifier(class_weight=\"balanced\", random_state=123)\n","# Create k-neighbours classifier\n","models[\"K-Neighbours\"] = KNeighborsClassifier()\n","\n","### Add new models here ###\n","# models[\"name\"] = model()"]},{"cell_type":"code","execution_count":null,"id":"2b75ec12","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:40:58.125554Z","iopub.status.busy":"2023-12-09T19:40:58.124911Z","iopub.status.idle":"2023-12-09T19:41:00.022152Z","shell.execute_reply":"2023-12-09T19:41:00.020978Z"},"papermill":{"duration":1.91413,"end_time":"2023-12-09T19:41:00.024795","exception":false,"start_time":"2023-12-09T19:40:58.110665","status":"completed"},"tags":[]},"outputs":[],"source":["# Validate models with accuracy\n","scores = list(map(lambda model: validate_model(model, X_train, y_train, cv=skf).mean(), models.values()))\n","scores = dict(zip(models.keys(), scores))\n","\n","# Validate models with a confusion matrix\n","confusion_matrices = list(map(lambda model: make_confusion_matrix(model, X_train, y_train, cv=skf), models.values()))\n","confusion_matrices = dict(zip(models.keys(), confusion_matrices))"]},{"cell_type":"code","execution_count":null,"id":"85b398fc","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:41:00.052591Z","iopub.status.busy":"2023-12-09T19:41:00.052159Z","iopub.status.idle":"2023-12-09T19:41:01.363056Z","shell.execute_reply":"2023-12-09T19:41:01.361933Z"},"papermill":{"duration":1.32836,"end_time":"2023-12-09T19:41:01.366241","exception":false,"start_time":"2023-12-09T19:41:00.037881","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","ncol = 2\n","model_num = len(models)\n","nrow = round(np.ceil(model_num / ncol))\n","\n","fig, axes = plt.subplots(nrow, ncol)\n","\n","fig.set_figheight(3 * nrow)\n","fig.set_figwidth(3 * ncol)\n","\n","# Print validation profile for each model\n","for idx, (name, model) in enumerate(models.items()):\n","\n","    print(f\"Accuracy of {name}: {scores[name].mean():.3f}\")\n","    \n","    if idx == 0:\n","        row_idx = 0\n","    elif idx % ncol == 0:\n","        row_idx += 1\n","    \n","    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrices[name])\n","    disp.plot(ax=axes[row_idx, idx % ncol])\n","    disp.ax_.set_title(name)\n","\n","plt.tight_layout()"]},{"cell_type":"markdown","id":"d2bf7a2d","metadata":{"papermill":{"duration":0.013826,"end_time":"2023-12-09T19:41:01.394302","exception":false,"start_time":"2023-12-09T19:41:01.380476","status":"completed"},"tags":[]},"source":["# Hyperparameter Turning\n","\n","_How can we optimise the selected model to improve performance?_ The answer to this question lies in **hyperparameter tuning**. Here, the goal consists in finding the combination of values for the model hyperparameters in order to achieve the best possible performance. This is usually done with a grid search, which can be either full or randomised. The former searches over the full grid for the actual best combination, whereas the latter only searches over a random subset of the grid. Randomised grid search reduces the computational demand while still providing a nearly optimal combination of values, for which reason it is applied below."]},{"cell_type":"code","execution_count":null,"id":"8feb3132","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:41:01.480563Z","iopub.status.busy":"2023-12-09T19:41:01.479519Z","iopub.status.idle":"2023-12-09T19:41:01.489078Z","shell.execute_reply":"2023-12-09T19:41:01.488319Z"},"papermill":{"duration":0.082984,"end_time":"2023-12-09T19:41:01.490943","exception":false,"start_time":"2023-12-09T19:41:01.407959","status":"completed"},"tags":[]},"outputs":[],"source":["# Select the best classifier algorithm\n","selected_model = models[max(scores, key=scores.get)]\n","\n","# View the best classifier algorithm\n","selected_model"]},{"cell_type":"code","execution_count":null,"id":"381f1e17","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:41:01.52407Z","iopub.status.busy":"2023-12-09T19:41:01.523346Z","iopub.status.idle":"2023-12-09T19:41:01.529545Z","shell.execute_reply":"2023-12-09T19:41:01.528735Z"},"papermill":{"duration":0.02492,"end_time":"2023-12-09T19:41:01.531608","exception":false,"start_time":"2023-12-09T19:41:01.506688","status":"completed"},"tags":[]},"outputs":[],"source":["from functools import reduce\n","\n","# Provide parameters to optimise and grid values\n","param_grid = {\"max_depth\": [200, 500, 800, 1100],\n","              \"n_estimators\": [100, 200, 300, 400]}\n","\n","# Convert parameter grid to list\n","grid_values = list(param_grid.values())\n","# Compute number of possible combinations (full grid)\n","full_search_iter = reduce(lambda x, y: x * len(y), grid_values[1:], len(grid_values[0]))\n","\n","# Perform randomised search for best combination of parameters\n","tuned_models = ms.RandomizedSearchCV(\n","    estimator=selected_model,\n","    param_distributions=param_grid,\n","    n_iter=min(full_search_iter, 60), \n","    scoring=make_scorer(accuracy_score),\n","    cv=skf,\n","    refit=True,\n","    n_jobs=-1\n",")"]},{"cell_type":"code","execution_count":null,"id":"cc221119","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:41:01.564636Z","iopub.status.busy":"2023-12-09T19:41:01.563978Z","iopub.status.idle":"2023-12-09T19:41:16.44195Z","shell.execute_reply":"2023-12-09T19:41:16.440601Z"},"papermill":{"duration":14.897815,"end_time":"2023-12-09T19:41:16.444531","exception":false,"start_time":"2023-12-09T19:41:01.546716","status":"completed"},"tags":[]},"outputs":[],"source":["# Train tuned models\n","tuned_models.fit(X_train, y_train)\n","\n","# Select the best model in terms of accuracy\n","tuned_model = tuned_models.best_estimator_\n","\n","# View the best model\n","tuned_model"]},{"cell_type":"markdown","id":"b873f812","metadata":{"papermill":{"duration":0.015043,"end_time":"2023-12-09T19:41:16.475416","exception":false,"start_time":"2023-12-09T19:41:16.460373","status":"completed"},"tags":[]},"source":["# Model Assessment\n","\n","After selecting and tuning the best model, it is finally time to test its performance on the test set. Getting nervous, how well will it do?"]},{"cell_type":"code","execution_count":null,"id":"c5490535","metadata":{"execution":{"iopub.execute_input":"2023-12-09T19:41:16.507701Z","iopub.status.busy":"2023-12-09T19:41:16.507321Z","iopub.status.idle":"2023-12-09T19:41:16.536264Z","shell.execute_reply":"2023-12-09T19:41:16.534829Z"},"papermill":{"duration":0.048068,"end_time":"2023-12-09T19:41:16.538717","exception":false,"start_time":"2023-12-09T19:41:16.490649","status":"completed"},"tags":[]},"outputs":[],"source":["# Predict CDR of test set with best tuned model\n","y_pred = tuned_model.predict(X_test)\n","\n","print(f\"Accuracy of best tuned model: {accuracy_score(y_test, y_pred):.3f}\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":1980,"sourceId":3398,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":30.130994,"end_time":"2023-12-09T19:41:19.182062","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-12-09T19:40:49.051068","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}
